{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8734f6",
   "metadata": {
    "gather": {
     "logged": 1652119071245
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import afqinsight.nn.tf_models as nn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from afqinsight.datasets import AFQDataset\n",
    "from afqinsight.nn.tf_models import cnn_lenet, mlp4, cnn_vgg, lstm1v0, lstm1, lstm2, blstm1, blstm2, lstm_fcn, cnn_resnet\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os.path\n",
    "# Harmonization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neurocombat_sklearn import CombatModel\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "\n",
    "import pickle\n",
    "from tools import load_data, model_fit, fit_and_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cc071c-aec4-4786-9dd3-932697bf5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale = 1/5 \n",
    "# scale = 1/10\n",
    "# scale = 1/20 \n",
    "# scale = 1/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5edc8-9195-46ff-99aa-7424799bf1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tf_aug(X_in, scaler=scale):\n",
    "#     X_out = np.zeros_like(X_in)\n",
    "#     for channel in range(X_in.shape[-1]):\n",
    "#         this_X = X_in[..., channel][np.newaxis, ..., np.newaxis]\n",
    "#         scale = np.abs(np.max(this_X) - np.min(this_X)) * scaler\n",
    "#         this_X = jitter(this_X, sigma=scale)\n",
    "#         this_X = scaling(this_X, sigma=scale)\n",
    "#         this_X = time_warp(this_X, sigma=scale)\n",
    "#         this_X = window_warp(this_X, window_ratio=scale)\n",
    "#         X_out[..., channel] = this_X[0, ..., 0]\n",
    "#     return X_out\n",
    "\n",
    "\n",
    "# def augment_this(X_in, y_in):\n",
    "#     X_out = tf.numpy_function(tf_aug, [X_in], tf.float32)    \n",
    "#     return X_out, y_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81336e-de7f-4f39-b629-119be45ce679",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, site = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ce224-53e2-496b-9135-791d99187b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "  \"cnn_lenet\": {\"model\": cnn_lenet, \"lr\": 0.001}, \n",
    "  # \"mlp4\": {\"model\": mlp4, \"lr\": 0.001},\n",
    "  # \"cnn_vgg\": {\"model\": cnn_vgg, \"lr\": 0.001},\n",
    "  # \"lstm1v0\": {\"model\": lstm1v0, \"lr\": 0.01},\n",
    "  # \"lstm1\": {\"model\": lstm1, \"lr\": 0.01},\n",
    "  # \"lstm2\": {\"model\": lstm2, \"lr\": 0.01},\n",
    "  # \"blstm1\": {\"model\": blstm1, \"lr\": 0.01},\n",
    "  # \"blstm2\": {\"model\": blstm1, \"lr\": 0.01},\n",
    "  # \"lstm_fcn\": {\"model\": lstm_fcn, \"lr\": 0.01},\n",
    "#   \"cnn_resnet\": {\"model\": cnn_resnet, \"lr\": 0.01}\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abcbeb5-f109-4d84-90e1-92aecc61b5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f3387-bb0c-4b6c-ac9a-8f6e87be0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated once with this code and then hard-coded:\n",
    "# seeds = np.array([np.abs(np.floor(np.random.randn()*1000)) for ii in range(n_runs)], dtype=int)\n",
    "\n",
    "seeds = np.array([484, 645, 714, 244, 215, 1502, 1334, 1576, 469, 1795])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e88d0ab-5a49-46c0-80e2-fabffb498a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_eval = []\n",
    "dfs_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd035f48",
   "metadata": {
    "gather": {
     "logged": 1652213549742
    }
   },
   "outputs": [],
   "source": [
    "for model in model_dict:\n",
    "    print(\"##################################################\")\n",
    "    print(\"model: \", model)\n",
    "    for ii in range(n_runs): \n",
    "        print(\"run: \", ii)\n",
    "        this_eval, this_pred = fit_and_eval(\n",
    "            model, \n",
    "            X, \n",
    "            y, \n",
    "            random_state=seeds[ii],\n",
    "            train_size=None)\n",
    "        this_eval[\"run\"] = ii\n",
    "        this_pred[\"run\"] = ii\n",
    "        dfs_eval.append(this_eval)\n",
    "        dfs_pred.append(this_pred)\n",
    "        # Save evaluation metrics\n",
    "        one_df = pd.concat(dfs_eval)\n",
    "        one_df.to_csv(\"lenet_1_eval.csv\")\n",
    "        # Save predictions and test values:\n",
    "        one_df = pd.concat(dfs_pred)\n",
    "        one_df.to_csv(\"lenet_1_pred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174eac28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to try different training sample sizes: s\n",
    "# (1453, 1000, 700, 350, 175)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "azureml_py38_pt_tf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
